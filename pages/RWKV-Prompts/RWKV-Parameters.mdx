---
title: RWKV解码参数 - RWKV提示词
description: RWKV模型解码参数介绍，包括Temperature、Top_P、Presence Penalty和Frequency Penalty等参数的效果和推荐配置。
keywords: RWKV解码参数,RWKV采样参数,RWKV参数配置,RWKV参数推荐
---

import { Callout } from 'nextra/components'
import { Steps } from 'nextra/components'
import { Cards, Card } from 'nextra/components'
import { Tabs } from 'nextra/components'
import { LinkToSvg } from '/components/svgs.tsx'

你可能注意到了，很多 RWKV 部署/体验工具都支持调整 `Temperature`、`Top_P` 、`Presence Penalty `、`Frequency Penalty`等参数，这些参数是 RWKV 模型的“解码参数”（也可称之为“采样参数”）。

通过**调整解码参数**，可以改变模型的生成效果。

即使是使用同一个 Prompt、同一个 RWKV 模型，不同的参数配置可能获得截然不同的回答。

## RWKV 模型的解码参数

RWKV 主要解码参数对应的效果如下：

| 参数                | 效果                                                                                                                                                            |
| ------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `Top_P`             | 选择累积概率达到 $P$ 值的前 $N$ 个 token 作为候选集。如设置成 0.1 则考虑前 10% , 生成内容质量更高但更保守。设置成 1 则内容质量降低但更多样。 |
| `Temperature`       | 温度参数 $T$ 通过修改 logits 的缩放比例控制生成结果的随机性。高温会使概率分布更均匀，增加生成内容的随机性；低温则使模型更倾向于选择概率最高的 token。                                                                              |
| `Presence penalty`  | 存在惩罚，对**已出现过的所有 token** 施加**固定惩罚**，从而增加了模型生成新 token 的可能性。                                                                 |
| `Frequency Penalty` | 频率惩罚，根据 **token 出现的次数**进行**累加惩罚**，从而减少模型频繁地重复相同内容的可能性。 |
| `max_tokens`        | 模型生成文本时的最大 token 数，可以理解为“模型一次最多生成多少字”（换算比例约 1:0.7 ）。                                                                 |

<Callout type="info" emoji="ℹ️">
接下来，我们将 RWKV 模型比喻为一名作家，并使用**更通俗易懂的说法**解释这些参数的作用。
</Callout>

### **`Top_P` 参数**[#Top_P]
<Tabs items={['参数作用', '参数建议']}>
<Tabs.Tab>
`Top_P` 就像一位主编，它决定 RWKV 这位作家**可以使用多少词汇**。假设当前可选的词汇有 100 个，那么：  

- `Top_P = 0.2` 是一位**非常严苛**的主编，只允许 RWKV 使用最常见、最符合逻辑的词汇（按照 Zipf 语言分布，实际可选词可能仅有 3 ~ 8 个）。  
- `Top_P = 1` 是一位**非常宽松**的主编，RWKV 可以自由选择所有 100 个词汇，生成更加多样化的文本。  

</Tabs.Tab>
<Tabs.Tab>
**`Top_P` 调整建议**
| 使用场景 | 推荐 `Top_P` | 适用情况 |
|----------|------------|---------|
| 创意写作、故事生成 | 0.5 ~ 0.7 | 允许一定程度的发散，避免内容过于死板，但超过 0.7 可能会偏离主题 |
| 机械式问答、摘要、翻译 | 0 ~ 0.5（甚至 0 ~ 0.3） | 重点保持精准、减少不必要的发散 |
| 确定性回答（是/否、ABCD、1234） | 0 | 只允许最确定的答案，完全避免随机性 |
</Tabs.Tab>
</Tabs>


### `Temperature` 温度参数[#Temperature]
<Tabs items={['参数作用', '参数建议']}>
<Tabs.Tab>
增加 `Temperature` 温度参数就像给 RWKV 这位作家“喝酒”。增加温度参数会增大文字的**随机性**，使内容更多样化，但太高**可能使生成的内容不通顺或不合常理**。

- 如果温度较低（如 0.5 以下），模型会像严谨的学术作家一样，只使用最通用最稳健的词汇。比如“阳光明媚” 会描述为 “日照充足”。更严谨，适合正式写作或精确回答。
- 如果温度较高（如 1.5 以上），模型会像喝醉的诗人一样，使用更多不常见的词汇，比如把彩虹描述为"宇宙的彩色伤口"。更有创造力，但可能出现不连贯表达。

</Tabs.Tab>
<Tabs.Tab>
**`Temperature` 参数建议搭配 `Top_P` 一起调整：**

| `Top_P` | 推荐 `Temperature` | 适用情况 |
|---------|------------------|---------|
| ≥ 0.7   | 1                | 适用于创意写作，保持稳定多样性 |
| 0.3 ~ 0.7 | 1 ~ 1.3 | 适度增加随机性，避免内容太死板 |
| 0.3 | 1 ~ 1.5 | 采样范围有限，需要适当增加随机性 |
| ≤ 0.2 | 1 ~ 2   | 低 `Top_P` 容易生成重复内容，提高 `Temperature` 增加变化性 |

<Callout type="warning" emoji="⚠️">
**`Top_P` 极低时，需适当提高 `Temperature`（1 或以上），避免文本陷入死循环或重复**。  
</Callout>
</Tabs.Tab>

</Tabs>

### `Presence penalty` 参数[#Presence-Penalty]

<Tabs items={['参数作用', '参数建议']}>
<Tabs.Tab>
`Presence penalty` 可以防止同一个词被反复使用，但不会因多次出现而增加惩罚力度。它的本质类似于一个动态更新的“禁用词库”：

- 每当模型生成一个新词，该词会立即被加入“禁用词库”
- 在后续生成过程中，该词**出现的概率会被固定降低一定值**（例如 0.5）

假设当前的 `Presence penalty` 参数值是 0.5， “美丽” 这个词在原始情况下的生成概率为 10%。那么

- 若“美丽”这个词此前已出现过，则其生成概率会被扣除固定值，对应 logits 下降，最终概率降低
- 但其他未出现的词不受影响，其 logits 不变，最终概率可能因归一化略有调整
</Tabs.Tab>
<Tabs.Tab>
**`Presence penalty` 参数推荐值：**

| `Top_P`  | 推荐 `Presence Penalty` | 推荐理由 |
|----------|----------------------|---------|
| 0.7      | 0.2 ~ 0.4        | 允许较多词汇多样性，适当增加 `Presence Penalty` 可防止长文本中过度重复相同主题或短语。 |
| 0.5      | 0.3 ~ 0.6        | 适中搭配，保持连贯性的同时减少重复，适用于大多数任务。 |
| 0.3      | 0.5 ~ 0.7        | `Top_P` 较低，采样范围受限，增加 `Presence Penalty` 避免相同的词或短语反复出现。 |
| ≤ 0.2    | 0 ~ 0.1，建议 `Temperature` 1 ~ 2 | `Top_P` 过低时**可用的词汇很少**，不应强行惩罚已出现的词，否则会造成表达异常，建议通过提高 `Temperature` 增强变化性。 |

</Tabs.Tab>
<Callout type="warning" emoji="⚠️">
`Presence penalty` 数值过高，可能会导致模型**过度避免重复用词**，使文本变得不自然或不连贯。在 `Top_P` 极低等极端情况下，可能影响标点符号的使用，甚至生成异常字符或难以理解的文本。
</Callout>
</Tabs>

### `Frequency Penalty` 参数[#Frequency-Penalty]

<Tabs items={['参数作用', '参数建议']}>
<Tabs.Tab>
`Frequency Penalty` 用于**抑制高频重复词**，它会根据**某个词在已生成文本中出现的次数**来降低其后续出现的概率。出现次数越多，惩罚越强。

可通过增加 `Frequency Penalty` 参数来**减少“然后”、“嗯嗯”等口头禅式的重复**，从而让生成的文本更加自然流畅。

假设当前的 `Frequency Penalty` 设为 `0.3`，某个词“美丽”的原始生成概率是 `10%`，但此前已经生成过三次：

- 计算惩罚后，"美丽" 的新概率 = `10% - (3 × 0.3)` = `9.1%`
- 如果再生成一次（累计四次出现），则新一轮惩罚扣除 `4 × 0.3 = 1.2%`

<Callout type="warning" emoji="⚠️">
以上示例仅用于说明 `Frequency Penalty` 的作用，实际计算通常是对 logits 进行乘法调整，而不是简单的减法操作。
</Callout>

</Tabs.Tab>
<Tabs.Tab>
| `Top_P`  | 推荐 `Frequency Penalty` | 适用情况 |
|----------|----------------------|---------|
| 0.7      | 0.2 ~ 0.5              | `Top_P` 很高时（如 `0.7`），模型可选词较多，提高 `Frequency Penalty` 可以减少冗余词汇的重复。   |
| 0.5      | 0.3 ~ 0.6              | 适用于大多数场景，既减少重复，又不影响表达 |
| 0.3      | 0.4 ~ 0.7              | `Top_P` 低时，需更高的 `Frequency Penalty` 防止重复 |
| ≤ 0.2    | 0 ~ 0.1，且建议 `Temperature` 1 ~ 2 |  **`Top_P` 极低**（≤ `0.2`）时，建议减少 `Frequency Penalty`，改为提高 `Temperature`，否则可能导致文本异常、不流畅。  |
</Tabs.Tab>
</Tabs>

## 不同任务的参数组合[#RWKV-Parameters-for-Tasks]

我们为不同的任务提供了一些推荐的参数：

<Tabs items={['创意类内容创作', '结构化写作', '机械任务']}>
<Tabs.Tab>

创意类内容需要更多的**随机性**和**开放性**，让模型能生成更具想象力的表达，因此 `Top_P` 和 `Temperature` 设得较高，而 `Presence Penalty` 和 `Frequency Penalty` 适中，以避免过于重复。

| 任务类型 | `Top_P` | `Temperature` | `Presence Penalty` | `Frequency Penalty` |
|---------|--------|--------------|------------------|------------------|
| 故事创作 | 0.8 | 1.3 | 0.4 | 0.5 |
| 诗歌 / 文学 | 0.9 | 1.8 | 0.3 | 0.4 |
| 广告文案 / 营销 | 0.7 | 1.2 | 0.5 | 0.6 |
| 自由写作 | 0.85 | 1.5 | 0.4 | 0.5 |
</Tabs.Tab>

<Tabs.Tab>

结构化写作需要一定的创造力，但也要保证逻辑和条理，因此 `Top_P` 和 `Temperature` 适中，同时适当增加 `Presence Penalty` 和 `Frequency Penalty` 以减少重复表达。

| 任务类型 | `Top_P` | `Temperature` | `Presence Penalty` | `Frequency Penalty` |
|---------|--------|--------------|------------------|------------------|
| 新闻 / 文章 | 0.6 | 1.1 | 0.3 | 0.4 |
| 论文 / 研究报告 | 0.4 | 0.9 | 0.4 | 0.5 |
| 剧本 / 对话 | 0.7 | 1.3 | 0.5 | 0.6 |
| 产品描述 | 0.5 | 1.0 | 0.3 | 0.4 |
</Tabs.Tab>
<Tabs.Tab>

机械任务需要精确和一致性，或者需要严格遵循特定格式。因此 `Temperature` 和 `Top_P`较低，同时尽量降低 `Presence Penalty` 和 `Frequency Penalty` ，以免影响常见词的使用。

| 任务类型 | `Top_P` | `Temperature` | `Presence Penalty` | `Frequency Penalty` |
|---------|--------|--------------|------------------|------------------|
| 问答 / 事实性回答 | 0.2 | 0.8 | 0.1 | 0.2 |
| 摘要 / 复述 | 0.3 | 1.0 | 0.2 | 0.3 |
| 翻译 | 0.3 | 0.9 | 0.2 | 0.3 |
| 公式 / 代码生成 | 0.1 | 0.7 | 0.1 | 0.2 |
| 选择题、判断题 | 0 | 0.7 | 0.1 | 0.2 |
</Tabs.Tab>

可以根据具体任务再微调参数，调整原则：

- **`Top_P` 控制选词范围**：数值高更多样，数值低更精准。  
- **`Temperature` 控制随机性**：数值高更有创意，数值低更稳定。  
- **`Presence Penalty` 控制全局重复**：数值高减少整体重复，适用于写作。  
- **`Frequency Penalty` 控制频繁重复**：数值高减少口头禅、短句重复，适用于对话和正式写作。  
</Tabs>
