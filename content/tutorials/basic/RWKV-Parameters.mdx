---
title: 如何调整 RWKV 的解码参数
description: 介绍RWKV的解码参数，包括Temperature、Top_P、Presence Penalty和Frequency Penalty等参数的效果和推荐配置。
keywords: [RWKV解码参数, RWKV采样参数, RWKV参数配置, RWKV参数推荐]
---

import { Tab, Tabs } from 'fumadocs-ui/components/tabs'
import { CallOut } from 'components-docs/call-out/call-out.tsx'

你可能注意到了，很多 RWKV 部署/体验工具都支持调整 `Temperature`、`Top_P` 、`Presence Penalty `、`Frequency Penalty`等参数，这些参数是 RWKV 模型的“解码参数”（也可称之为“采样参数”）。

通过**调整解码参数**，可以改变模型的生成效果。

即使是使用同一个 Prompt、同一个 RWKV 模型，不同的参数配置可能获得截然不同的回答。

## 视频教程

<div className="iframe-container">
 <iframe 
 src="https://player.bilibili.com/player.html?isOutside=true&aid=114142983750961&bvid=BV1iMRnY8ENn&cid=28809627890&poster=1&p=0&high_quality=1&autoplay=0"
 scrolling="no"
 frameBorder="0"
 allowFullScreen={true}
 sandbox="allow-top-navigation allow-same-origin allow-forms allow-scripts"
>
</iframe>
</div>
<CallOut type="info" >
高画质视频请[跳转到 B 站](https://www.bilibili.com/video/BV1iMRnY8ENn)观看。
</CallOut>

## RWKV 模型的解码参数

RWKV 主要解码参数对应的效果如下：

| 参数                | 效果                                                                                                                                                            |
| ------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `Temperature`       | 温度参数 $T$ 通过修改 logits 的缩放比例控制生成结果的随机性。高温会使概率分布更均匀，增加生成内容的随机性；低温则使模型更倾向于选择概率最高的 token                   |
| `Top_P`             | 选择累积概率达到 $P$ 值的前 $N$ 个 token 作为候选集。如设置成 0.1 则考虑前 10% , 生成内容质量更高但更保守。设置成 1 则内容质量降低但更多样 |
| `Presence Penalty`  | 存在惩罚，对**已出现过的所有 token** 施加**固定惩罚**，从而增加了模型生成新 token 的可能性                                                               |
| `Frequency Penalty` | 频率惩罚，根据 **token 出现的次数**进行**累加惩罚**，从而减少模型频繁地重复相同内容的可能性 |
| `Penalty Decay`     | 惩罚衰减参数，用于控制 `Presence Penalty` 和 `Frequency Penalty` 的衰减速度。数值越接近 1，惩罚衰减得越慢；数值越小，则衰减越快 |
| `max_tokens`        | 模型生成文本时的最大 token 数，可以理解为“模型一次最多生成多少字”                                                                 |

<CallOut type="info" >
接下来，我们将 RWKV 模型比喻为一名作家，并使用**更通俗易懂的说法**解释这些参数的作用。
</CallOut>

### `Top_P` 参数[#Top_P]

`Top_P` 就像一位主编，它决定 RWKV 这位作家**可以使用多少词汇**。假设当前可选的词汇有 100 个，那么：  

- `Top_P = 0.2` 是一位**非常严苛**的主编，只允许 RWKV 使用最常见、最符合逻辑的词汇（按照 Zipf 语言分布，实际可选词可能仅有 3 ~ 8 个）。  
- `Top_P = 1` 是一位**非常宽松**的主编，RWKV 可以自由选择所有 100 个词汇，生成更加多样化的文本。  

**`Top_P` 调整建议**：

| 使用场景 | 推荐 `Top_P` | 适用情况 |
|----------|------------|---------|
| 创意写作、故事生成 | 0.7 | 允许一定程度的发散，避免内容过于死板，同时不会偏离主题 |
| 机械式问答、摘要、翻译 | 0.3 | 重点保持精准、减少不必要的发散 |
| 确定性回答（是/否、ABCD、1234） | 0 | 只允许最确定的答案，完全避免随机性 |

### `Temperature` 温度参数[#Temperature]


增加 `Temperature` 温度参数就像给 RWKV 这位作家“喝酒”。增加温度参数会增大文字的**随机性**，使内容更多样化，但太高**可能使生成的内容不通顺或不合常理**。

- 如果温度较低（如 0.5 以下），模型会像严谨的学术作家一样，只使用最通用最稳健的词汇。比如“阳光明媚” 会描述为 “日照充足”。更严谨，适合正式写作或精确回答。
- 如果温度较高（如 1.5 以上），模型会像喝醉的诗人一样，使用更多不常见的词汇，比如把彩虹描述为"宇宙的彩色伤口"。更有创造力，但可能出现不连贯表达。

<CallOut type="warning" >
**`Top_P` 极低时，需适当提高 `Temperature`（1 以上），避免文本陷入死循环或重复**。  
</CallOut>

### `Presence Penalty` 参数[#Presence-Penalty]


`Presence Penalty` 可以防止同一个词被反复使用，但不会因多次出现而增加惩罚力度。它的本质类似于一个动态更新的“禁用词库”：

- 每当模型生成一个新词，该词会立即被加入“禁用词库”
- 在后续生成过程中，该词**出现的概率会被固定降低一定值**（例如 0.5）

假设当前的 `Presence Penalty` 参数值是 0.5， “美丽” 这个词在原始情况下的生成概率为 10%。那么

- 若“美丽”这个词此前已出现过，则其生成概率会被扣除固定值，对应 logits 下降，最终概率降低
- 但其他未出现的词不受影响，其 logits 不变，最终概率可能因归一化略有调整

<CallOut type="warning" >
`Presence Penalty` 数值过高，可能会导致模型**过度避免重复用词**，使文本变得不自然或不连贯。在 `Top_P` 极低等极端情况下，可能影响标点符号的使用，甚至生成异常字符或难以理解的文本。
</CallOut>

### `Frequency Penalty` 参数[#Frequency-Penalty]


`Frequency Penalty` 用于**抑制高频重复词**，它会根据**某个词在已生成文本中出现的次数**来降低其后续出现的概率。出现次数越多，惩罚越强。可通过增加 `Frequency Penalty` 参数来**减少“然后”、“嗯嗯”等口头禅式的重复**，从而让生成的文本更加自然流畅。

假设当前的 `Frequency Penalty` 设为 `0.3`，某个词“美丽”的原始生成概率是 `10%`，但此前已经生成过三次：

- 计算惩罚后，"美丽" 的新概率 = `10% - (3 × 0.3)` = `9.1%`
- 如果再生成一次（累计四次出现），则新一轮惩罚扣除 `4 × 0.3 = 1.2%`

<CallOut type="warning" >
以上示例仅用于说明 `Frequency Penalty` 的作用，实际计算通常是对 logits 进行乘法调整，而不是简单的减法操作。
</CallOut>

### `Penalty Decay` 参数[#Penalty-Decay]

<CallOut type="info" >
`Penalty Decay` 参数用于控制 `Presence Penalty` 和 `Frequency Penalty` 的衰减速度，它会根据 token 之间的距离，逐步减弱惩罚强度。
</CallOut>

假设 `Presence Penalty = 1`，而模型写下了：“美 好 的 天 气 …”。前面我们了解过， `Presence Penalty` 会对出现过的字添加惩罚，因为“美”已经在第一个位置出现过，`Presence Penalty = 1` 会大大降低模型再次生成“美”字的概率。

但是 `Presence Penalty` 惩罚的强度并不是一成不变的，在 `Penalty Decay` 参数的作用下，`Presence Penalty` 惩罚会随着文本的长度增加而逐步减弱，衰减公式： ${{实际惩罚}} = P_0 \cdot \gamma^d$，其中 $𝑃_0$ 是原始惩罚值，$γ$ 是 `Penalty Decay` 值，𝑑 是与“美”上次出现的位置的距离。

<CallOut type="tips" >
从公式可以看出来，惩罚减弱的速度由 `Penalty Decay` 参数的大小决定。`Penalty Decay` 参数的范围是 0.99 ~ 0.999，数值越接近 1，惩罚衰减得越慢；越小则衰减越快。
</CallOut>

如果把 RWKV 模型比作一位作家，那么 `Penalty Decay` 就是这位作家的**记性**：

- `Decay = 0.99` 时，RWKV 模型的**记性很差**。在生成 100 个字之后，它对第一个“美”字的惩罚值只剩下约 0.366（$Presence Penalty \cdot 0.99^{100} \approx 1.0 \cdot 0.366 \approx 0.366$）。此时模型已经忘记自己生成过“美”字了，模型**生成“美”字的概率很高**。
- `Decay = 0.999` 时，RWKV 模型的**记性很好**。在生成 100 个字之后，它对第一个“美”字的惩罚值仍然高达 0.905（$Presence Penalty \cdot 0.999^{100} \approx 1.0 \cdot 0.905 \approx 0.905$）。模型会牢记自己曾经生成过“美”字，此时**生成“美”字的概率很低**。


## 不同任务的推荐解码参数组合[#RWKV-Parameters-for-Tasks]

我们为不同的任务提供了一些推荐的参数：

| 任务类型 | Top_P | Temperature | Presence Penalty | Frequency Penalty | Penalty Decay |
|---------|--------|--------------|------------------|------------------|----------------|
| 内容创作，需要有创意 | 0.8 | 0.6 | 2.0 | 0.2 | 0.99 |
| 默认参数，适合对话或一般任务 | 0.3 | 1.0 | 0.5 | 0.5 | 0.996 |
| 保守型任务，回答稳定且准确 | 0.3 | 0.3 | 0.0 | 0.0 | 0.996 |
| 机械任务，无随机性 | 0.0 | 0.0 | 0.0 | 0.0 | 0.996 |

- **创意类内容创作**：典型的例子是小说、故事创作，需要平衡 `Temperature` 和 `Top_P`，提供更多的**随机性**和**开放性**，让模型能生成更具想象力的表达。
- **默认参数**：适合闲聊或其他普通任务，解码参数相对平衡，可以根据 “是否需要创意” 适当调整 `Temperature`。
- **保守型任务**：如知识问答、代码任务等，需要稳定且准确的回答，因此大幅降低 `Top_P` 和 `Temperature` ，同时移除 `Presence Penalty` 和 `Frequency Penalty` 带来的惩罚。
- **机械任务**：如选择题、判断题等，需要严格遵循特定格式，只输出唯一解。因此所有解码参数均设为 0 ，以取消随机性。

<CallOut type="tips" >
`Top_P = 0` 时， `Temperature` 参数会失效。
</CallOut>
